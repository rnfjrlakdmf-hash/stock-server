import requests
from bs4 import BeautifulSoup
import re
import concurrent.futures

def get_naver_disclosures(symbol: str):
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ íŠ¹ì • ì¢…ëª©ì˜ ìµœì‹  ì „ìê³µì‹œ ëª©ë¡ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    symbol: '005930' (ì¢…ëª©ì½”ë“œ, .KS/.KQ ì œê±° í•„ìš”)
    """
    # .KS, .KQ ì œê±°
    code = symbol.split('.')[0]
    
    # ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
    code = re.sub(r'[^0-9]', '', code)
    
    if len(code) != 6:
        return {"error": "Invalid Code"}

    url = f"https://finance.naver.com/item/news_notice.naver?code={code}&page=1"
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        res = requests.get(url, headers=headers)
        
        # Try decoding with utf-8 first (Modern Naver), then cp949 (Old Naver)
        try:
            html = res.content.decode('utf-8')
        except UnicodeDecodeError:
            try:
                html = res.content.decode('cp949')
            except UnicodeDecodeError:
                html = res.text # Fallback
            
        soup = BeautifulSoup(html, 'html.parser')
        
        disclosures = []
        
        # ê³µì‹œ í…Œì´ë¸” ì°¾ê¸°
        # 'type5' or 'type6' class used depending on page version
        rows = soup.select("table.type5 tbody tr, table.type6 tbody tr")
        
        for row in rows:
            cols = row.select("td")
            if len(cols) < 3:
                continue
                
            title_tag = cols[0].select_one("a")
            if not title_tag:
                continue
                
            title = title_tag.text.strip()
            link = "https://finance.naver.com" + title_tag['href']
            info = cols[1].text.strip() # ì •ë³´ì œê³µ (DART ë“±)
            date = cols[2].text.strip()
            
            # ì „ìê³µì‹œ(DART)ë§Œ í•„í„°ë§í•˜ê±°ë‚˜ ëª¨ë‘ í‘œì‹œ
            disclosures.append({
                "title": title,
                "link": link,
                "publisher": info,
                "date": date
            })
            
            if len(disclosures) >= 10:
                break
                
        return disclosures

    except Exception as e:
        print(f"Naver Disclosure Crawl Error: {e}")
        return []

def get_korean_name(symbol: str) -> str:
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì¢…ëª©ì˜ í•œê¸€ëª…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. (yfinanceì˜ ì˜ë¬¸ëª… ëŒ€ì²´ìš©)
    """
    try:
        code = symbol.split('.')[0]
        code = re.sub(r'[^0-9]', '', code)
        
        if len(code) != 6:
            return ""
            
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91"
        }
        res = requests.get(url, headers=headers)
        
        # Automatically detect encoding using chardet (via requests)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë©”ì¸ í˜ì´ì§€ ìƒë‹¨ì˜ ì¢…ëª©ëª… ì°¾ê¸°
        # <div class="wrap_company"><h2><a href="#">ì‚¼ì„±ì „ì</a></h2>...</div>
        h2 = soup.select_one(".wrap_company h2 a")
        if h2:
            return h2.text.strip()
            
        return ""
        return ""
    except Exception:
        return ""


def _get_soup(url, headers):
    try:
        res = requests.get(url, headers=headers, timeout=5)
        try:
            html = res.content.decode('utf-8')
        except UnicodeDecodeError:
            html = res.content.decode('cp949', 'ignore')
        return BeautifulSoup(html, 'html.parser')
    except Exception:
        return None

def get_naver_market_index_data():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    partial_data = {
        "exchange": [], "world_exchange": [], "oil": [], "gold": [], "interest": [], "raw_materials": []
    }
    try:
        soup_idx = _get_soup("https://finance.naver.com/marketindex/?tabSel=exchange#tab_section", headers)
        if soup_idx:
            # 1. Exchange Rates (FETCH ALL)
            # Naver lists major currencies in #exchangeList
            for li in soup_idx.select("#exchangeList li"):
                 # Layout: a.head > h3.h_lst > span.blind (Name)
                 # div.head_info > span.value, span.change
                 
                 name_tag = li.select_one("h3.h_lst span.blind")
                 if not name_tag: continue
                 
                 raw_name = name_tag.text.strip()
                 name = raw_name # Default
                 
                 # Format Name for better display (e.g., "ë¯¸êµ­ USD")
                 if "ë¯¸êµ­" in raw_name: name = "ë¯¸êµ­ USD"
                 elif "ì¼ë³¸" in raw_name: name = "ì¼ë³¸ JPY (100ì—”)"
                 elif "ìœ ëŸ½ì—°í•©" in raw_name: name = "ìœ ëŸ½ì—°í•© EUR"
                 elif "ì¤‘êµ­" in raw_name: name = "ì¤‘êµ­ CNY"
                 elif "í™ì½©" in raw_name: name = "í™ì½© HKD"
                 elif "ëŒ€ë§Œ" in raw_name: name = "ëŒ€ë§Œ TWD"
                 elif "ì˜êµ­" in raw_name: name = "ì˜êµ­ GBP"
                 elif "ìºë‚˜ë‹¤" in raw_name: name = "ìºë‚˜ë‹¤ CAD"
                 elif "ìŠ¤ìœ„ìŠ¤" in raw_name: name = "ìŠ¤ìœ„ìŠ¤ CHF"
                 elif "ë² íŠ¸ë‚¨" in raw_name: name = "ë² íŠ¸ë‚¨ VND (100ë™)"
                 elif "ëŸ¬ì‹œì•„" in raw_name: name = "ëŸ¬ì‹œì•„ RUB"
                 elif "ì¸ë„" in raw_name: name = "ì¸ë„ INR"
                 else: name = raw_name # Others

                 val = li.select_one("span.value").text.strip()
                 change = li.select_one("span.change").text.strip()
                 
                 # Up/Down Logic
                 head_info = li.select_one("div.head_info")
                 is_up = False
                 if head_info:
                     cls = head_info.get("class", [])
                     if "up" in cls or "plus" in cls: is_up = True
                 
                 partial_data["exchange"].append({"name": name, "price": val, "change": change, "is_up": is_up})

            # 2. World Exchange (Indices)
            for li in soup_idx.select("#worldExchangeList li"):
                 name = li.select_one("h3.h_lst span.blind").text.strip()
                 val = li.select_one("span.value").text.strip()
                 change = li.select_one("span.change").text.strip()
                 head_info = li.select_one("div.head_info")
                 is_up = False
                 if head_info and ("up" in head_info.get("class", []) or "plus" in head_info.get("class", [])):
                     is_up = True
                 partial_data["world_exchange"].append({"name": name, "price": val, "change": change, "is_up": is_up})

            # 3. Oil & Gold (Expanded)
            # Fetching from the main list often includes: WTI, Dubai, Brent, Gold(Domestic), Gold(Intl)
            # If the user wants "Everything" from the tab, we trust #oilGoldList provides the summary.
            for li in soup_idx.select("#oilGoldList li"):
                 name = li.select_one("h3.h_lst span.blind").text.strip()
                 val = li.select_one("span.value").text.strip()
                 change = li.select_one("span.change").text.strip()
                 
                 head_info = li.select_one("div.head_info")
                 is_up = False
                 if head_info:
                     cls = head_info.get("class", [])
                     if "up" in cls or "plus" in cls: is_up = True
                     
                 item = {"name": name, "price": val, "change": change, "is_up": is_up}
                 
                
                 # Categorize
                 if "ê¸ˆ" in name or "ê³¨ë“œ" in name: 
                     partial_data["gold"].append(item)
                 else: 
                     partial_data["oil"].append(item)

            # 4. Interest Rates (Explicit Fetch)
            soup_int = _get_soup("https://finance.naver.com/marketindex/?tabSel=interest", headers)
            if soup_int:
                # The active list is usually in .data_lst
                for li in soup_int.select(".data_lst li"):
                     name_tag = li.select_one("h3.h_lst span.blind")
                     if not name_tag: continue
                     name = name_tag.text.strip()
                     val = li.select_one("span.value").text.strip()
                     change = li.select_one("span.change").text.strip()
                     head_info = li.select_one("div.head_info")
                     is_up = False
                     if head_info:
                         cls = head_info.get("class", [])
                         if "up" in cls or "plus" in cls: is_up = True
                     partial_data["interest"].append({"name": name, "price": val, "change": change, "is_up": is_up})

            # 5. Raw Materials (Explicit Fetch)
            soup_mat = _get_soup("https://finance.naver.com/marketindex/?tabSel=materials", headers)
            if soup_mat:
                 for li in soup_mat.select(".data_lst li"):
                     name_tag = li.select_one("h3.h_lst span.blind")
                     if not name_tag: continue
                     name = name_tag.text.strip()
                     val = li.select_one("span.value").text.strip()
                     change = li.select_one("span.change").text.strip()
                     head_info = li.select_one("div.head_info")
                     is_up = False
                     if head_info:
                         cls = head_info.get("class", [])
                         if "up" in cls or "plus" in cls: is_up = True
                     partial_data["raw_materials"].append({"name": name, "price": val, "change": change, "is_up": is_up})
    except Exception as e:
        print(f"Market Index Error: {e}")
    return partial_data

def get_naver_sise_data():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    partial_data = {
        "top_sectors": [], "top_themes": [],
        "investor_items": {
            "foreigner_buy": [], "foreigner_sell": [], "institution_buy": [], "institution_sell": []
        }
    }
    try:
        soup_sise = _get_soup("https://finance.naver.com/sise/", headers)
        if soup_sise:
            # Sectors/Themes
            tables = soup_sise.select("table.type_1")
            if len(tables) > 0:
                for row in tables[0].select("tr")[2:]:
                    cols = row.select("td")
                    if len(cols) < 3: continue
                    link_tag = cols[0].select_one("a")
                    if not link_tag: continue
                    partial_data["top_sectors"].append({
                        "name": link_tag.text.strip(), 
                        "percent": cols[1].text.strip(),
                        "link": link_tag['href']
                    })
                    if len(partial_data["top_sectors"]) >= 10: break
            if len(tables) > 1:
                for row in tables[1].select("tr")[2:]:
                    cols = row.select("td")
                    if len(cols) < 3: continue
                    link_tag = cols[0].select_one("a")
                    if not link_tag: continue
                    partial_data["top_themes"].append({
                        "name": link_tag.text.strip(), 
                        "percent": cols[1].text.strip(),
                        "link": link_tag['href']
                    })
                    if len(partial_data["top_themes"]) >= 10: break

            # Investor Items
            def parse_sise_investor(tab_id):
                items = []
                container = soup_sise.select_one(tab_id)
                if not container: return []
                rows = container.select("tr")
                for row in rows:
                    cols = row.select("td")
                    if len(cols) < 4: continue
                    name_tag = cols[1].select_one("a")
                    if not name_tag: continue
                    name = name_tag.text.strip()
                    amount = cols[2].text.strip()
                    raw_change = cols[3].text.strip()
                    change = " ".join(raw_change.split())
                    is_up = False
                    if "rate_up" in str(cols[3]) or "up" in str(cols[3]) or "red" in str(cols[3]): is_up = True
                    if "ìƒìŠ¹" in change: is_up = True
                    change_val = re.sub(r'(ìƒìŠ¹|í•˜ë½|ë³´í•©)\s*', '', change).strip()
                    items.append({"name": name, "amount": amount, "change": change_val, "is_up": is_up})
                    if len(items) >= 5: break
                return items

            partial_data["investor_items"]["foreigner_buy"] = parse_sise_investor("#frgn_deal_tab_0")
            partial_data["investor_items"]["foreigner_sell"] = parse_sise_investor("#frgn_deal_tab_1")
            partial_data["investor_items"]["institution_buy"] = parse_sise_investor("#org_deal_tab_0")
            partial_data["investor_items"]["institution_sell"] = parse_sise_investor("#org_deal_tab_1")
    except Exception as e:
        print(f"Sise Error: {e}")
    return partial_data

def get_naver_main_data():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    partial_data = { "market_summary": { "kospi": None, "kosdaq": None, "kospi200": None } }
    try:
        soup_main = _get_soup("https://finance.naver.com/", headers)
        if soup_main:
            for p_type in ["kospi", "kosdaq", "kospi200"]:
                area = soup_main.select_one(f".{p_type}_area")
                if not area: continue
                
                # 1. Basic Index Info
                idx_val = area.select_one(".num_quot .num").text.strip()
                num2 = area.select_one(".num_quot .num2").text.strip()
                num3 = area.select_one(".num_quot .num3").text.strip()
                status_blind = area.select_one(".num_quot .blind")
                direction = "Equal"
                if status_blind:
                        txt = status_blind.text.strip()
                        if "ìƒìŠ¹" in txt: direction = "Up"
                        elif "í•˜ë½" in txt: direction = "Down"
                chart_img = ""
                img_tag = area.select_one(".chart_area img")
                if img_tag: chart_img = img_tag['src']
                
                # 2. Iterate DLs to find Investors, Stock Counts, Program Trading
                investors = { "personal": "0", "foreigner": "0", "institutional": "0" }
                stock_counts = None
                program_trading = None
                
                dls = area.select("dl")
                for dl in dls:
                    dts = dl.select("dt")
                    dds = dl.select("dd")
                    
                    if not dts or not dds: continue
                    
                    first_dt_text = dts[0].text.strip()
                    
                    # A. Investors
                    if "ê°œì¸" in first_dt_text or "ì™¸êµ­ì¸" in first_dt_text:
                        for dt, dd in zip(dts, dds):
                            label = dt.text.strip()
                            val = re.sub(r'[^0-9\-\+\,]', '', dd.text.strip())
                            if "ê°œì¸" in label: investors["personal"] = val
                            elif "ì™¸êµ­ì¸" in label: investors["foreigner"] = val
                            elif "ê¸°ê´€" in label: investors["institutional"] = val
                            
                    # B. Stock Counts
                    elif "ìƒí•œ" in first_dt_text or "ìƒìŠ¹" in first_dt_text:
                        counts = { "upper": "0", "up": "0", "equal": "0", "down": "0", "lower": "0" }
                        for dt, dd in zip(dts, dds):
                            label = dt.text.strip()
                            val = dd.text.strip()
                            if "ìƒí•œ" in label: counts["upper"] = val
                            elif "ìƒìŠ¹" in label: counts["up"] = val
                            elif "ë³´í•©" in label: counts["equal"] = val
                            elif "í•˜í•œ" in label: counts["lower"] = val
                            elif "í•˜ë½" in label: counts["down"] = val
                        stock_counts = counts
                        
                    # C. Program Trading
                    elif "í”„ë¡œê·¸ë¨" in first_dt_text:
                         if len(dds) >= 1:
                             program_trading = {
                                 "net": dds[0].text.strip(),
                                 "change": dds[1].text.strip() if len(dds) > 1 else "",
                                 "label": "í”„ë¡œê·¸ë¨"
                             }

                partial_data["market_summary"][p_type] = {
                    "value": idx_val,
                    "change": num2,
                    "percent": num3,
                    "direction": direction,
                    "chart": chart_img,
                    "investors": investors,
                    "stock_counts": stock_counts,
                    "program_trading": program_trading
                }
    except Exception as e:
        print(f"Main Page Error: {e}")
    return partial_data

def get_index_chart_data(symbol: str, timeframe: str = "day"):
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì§€ìˆ˜ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    symbol: KOSPI, KOSDAQ, KPI200
    timeframe: day (ì¼ë´‰), week(ì£¼ë´‰), month(ì›”ë´‰) - í˜„ì¬ëŠ” ì¼ë´‰/ë¶„ë´‰ ì§€ì› í™•ì¥ ê°€ëŠ¥
    """
    # ë§¤í•‘
    code = "KOSPI"
    if "KOSDAQ" in symbol.upper(): code = "KOSDAQ"
    elif "200" in symbol: code = "KPI200"

    # ë„¤ì´ë²„ ì°¨íŠ¸ API (XML ë°©ì‹ì´ ì•ˆì •ì )
    # https://fchart.stock.naver.com/sise.nhn?symbol=KOSPI&timeframe=day&count=60&requestType=0
    url = f"https://fchart.stock.naver.com/sise.nhn?symbol={code}&timeframe={timeframe}&count=60&requestType=0"
    
    try:
        import requests
        import xml.etree.ElementTree as ET
        
        res = requests.get(url)
        if res.status_code == 200:
            root = ET.fromstring(res.text)
            # <chartdata symbol="KOSPI" ...>
            #   <item data="20240101|2500.00|2550.00|2490.00|2530.00|..." />
            # </chartdata>
            
            chart_data = []
            for item in root.findall("item"):
                data_str = item.get("data")
                if data_str:
                    parts = data_str.split("|")
                    # ë‚ ì§œ, ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€, ê±°ë˜ëŸ‰
                    if len(parts) >= 5:
                        chart_data.append({
                            "date": parts[0],
                            "open": float(parts[1]),
                            "high": float(parts[2]),
                            "low": float(parts[3]),
                            "close": float(parts[4]),
                            # "volume": int(parts[5]) if len(parts) > 5 else 0
                        })
            return chart_data
    except Exception as e:
        print(f"Chart data fetch error: {e}")
    
    return []

def get_naver_market_dashboard():
    """
    ë„¤ì´ë²„ ê¸ˆìœµ ë°ìŠ¤í¬íƒ‘ ë©”ì¸ í˜ì´ì§€(or ì‹œì„¸ í˜ì´ì§€)ì—ì„œ 
    í™˜ìœ¨, ìœ ê°€, ê¸ˆë¦¬, ì›ìì¬, ì—…ì¢…ìƒìœ„, í…Œë§ˆìƒìœ„ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì¢…í•© ë°˜í™˜í•©ë‹ˆë‹¤.
    (í”„ë¡ íŠ¸ì—”ë“œ ëŒ€ì‹œë³´ë“œìš©) - ì´ì œ ë‚´ë¶€ í•¨ìˆ˜ë“¤ì„ ë³‘ë ¬ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    
    data = {
        "exchange": [],
        "world_exchange": [],
        "interest": [],
        "oil": [],
        "gold": [],
        "raw_materials": [],
        "top_sectors": [],
        "top_themes": [],
        "market_summary": {
            "kospi": None,
            "kosdaq": None
        },
        "investor_items": {
            "foreigner_buy": [],
            "foreigner_sell": [],
            "institution_buy": [],
            "institution_sell": []
        }
    }
    
    # Parallel Execution with Fallback
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            future_idx = executor.submit(get_naver_market_index_data)
            future_sise = executor.submit(get_naver_sise_data)
            future_main = executor.submit(get_naver_main_data)

            res_idx = future_idx.result(timeout=6)
            res_sise = future_sise.result(timeout=6)
            res_main = future_main.result(timeout=6)

            if res_idx: data.update(res_idx)
            if res_sise: 
                data["top_sectors"] = res_sise.get("top_sectors", [])
                data["top_themes"] = res_sise.get("top_themes", [])
                data["investor_items"] = res_sise.get("investor_items", data["investor_items"])
            if res_main: data["market_summary"] = res_main.get("market_summary", data["market_summary"])
            
    except Exception as e:
        print(f"Parallel Execution Error: {e}, falling back to sequential")
        try:
            res_idx = get_naver_market_index_data()
            if res_idx: data.update(res_idx)
            
            res_sise = get_naver_sise_data()
            if res_sise: 
                data["top_sectors"] = res_sise.get("top_sectors", [])
                data["top_themes"] = res_sise.get("top_themes", [])
                data["investor_items"] = res_sise.get("investor_items", data["investor_items"])
                
            res_main = get_naver_main_data()
            if res_main: data["market_summary"] = res_main.get("market_summary", data["market_summary"])
        except Exception as e2:
                print(f"Sequential Fallback Error: {e2}")

    return data

def get_ipo_data():
    """
    38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ IPO ì¼ì • í¬ë¡¤ë§
    http://www.38.co.kr/html/fund/index.htm?o=k
    """
    url = "http://www.38.co.kr/html/fund/index.htm?o=k"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91"
    }
    
    ipo_list = []
    
    try:
        res = requests.get(url, headers=headers)
        # 38.co.kr uses cp949/euc-kr
        try:
            html = res.content.decode('utf-8')
        except UnicodeDecodeError:
            html = res.content.decode('cp949', 'ignore')
        soup = BeautifulSoup(html, 'html.parser')
        
        target_table = None
        # Use simple find_all "tr" to search broadly first
        all_rows = soup.find_all("tr")
        for row in all_rows:
            text = row.get_text()
            if "ì¢…ëª©ëª…" in text and "ê³µëª¨ì£¼ì¼ì •" in text:
                 # Found the header row. Now find the parent table.
                 target_table = row.find_parent("table")
                 break
        
        if not target_table:
            return []

        # Get all rows in the table (flattening thead/tbody)
        table_rows = target_table.find_all("tr")
        
        # Find index of header row
        start_idx = -1
        for i, tr in enumerate(table_rows):
             if "ì¢…ëª©ëª…" in tr.text and "ê³µëª¨ì£¼ì¼ì •" in tr.text:
                 start_idx = i
                 break
        
        if start_idx == -1: return []
        
        # Parse data rows
        data_rows = table_rows[start_idx+1:]
        
        for row in data_rows:
            cols = row.select("td")
            if len(cols) < 5: continue
            
            # Col 0: Name, Col 1: Schedule, Col 2: Fixed Price, Col 3: Band
            name = cols[0].text.strip().replace('\xa0', '')
            schedule = cols[1].text.strip().replace('\xa0', '')
            
            # [Fix] Strict Filtering
            # 1. Skip News/Ads (start with [ or contain 'ë‰´ìŠ¤')
            if name.startswith("[") or "ë‰´ìŠ¤" in name:
                continue
                
            # 2. Skip Invalid Schedule (must be at least 5 chars and have separators)
            if not schedule or len(schedule) < 5 or ("~" not in schedule and "." not in schedule):
                continue

            fixed_price = cols[2].text.strip().replace('\xa0', '')
            price_band = cols[3].text.strip().replace('\xa0', '')
            
            if not name: continue
            
            ipo_list.append({
                "name": name,
                "listing_date": "ë¯¸ì •", # This page usually lists subscription schedule only
                "subscription_date": schedule,
                "price_band": price_band,
                "fixed_price": fixed_price
            })
            
            if len(ipo_list) >= 5: # Top 5
                break
                
    except Exception as e:
        print(f"IPO Crawl Error: {e}")
        
    return ipo_list

def get_live_investor_estimates(symbol: str):
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì¥ì¤‘ ì ì • íˆ¬ìì(ì™¸êµ­ì¸/ê¸°ê´€) ë™í–¥ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    URL: https://finance.naver.com/item/frgn.naver?code={code}
    """
    code = symbol.split('.')[0]
    code = re.sub(r'[^0-9]', '', code)
    if len(code) != 6: return None

    url = f"https://finance.naver.com/item/frgn.naver?code={code}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }
    
    try:
        res = requests.get(url, headers=headers)
        # cp949 decoding
        try:
            html = res.content.decode('utf-8')
        except UnicodeDecodeError:
            html = res.content.decode('cp949', 'ignore')
        soup = BeautifulSoup(html, 'html.parser')
        
        # 1. ì ì • ì¶”ê³„ í…Œì´ë¸” (slight variation in class/id)
        # Usually it's in a table next to or below the main daily trends
        # Look for "ì ì •ì¶”ê³„" text
        
        # In the new interface, it might be in a specific scraping target
        # Let's try finding the table with headers Time/Foreigner/Institution
        
        estimates = []
        
        # Table selection strategy: Look for table with "ì ì •" in summary or caption
        # Or locate by section header
        
        # Naver Finance often puts this in a table class 'type2' inside a div with specific ID or logic.
        # But specifically, there is often a table showing 09:30, 10:00, 11:30...
        
        sections = soup.select(".sub_section")
        target_table = None
        
        for sec in sections:
            if "ì ì •" in sec.text:
                target_table = sec.select_one("table")
                break
        
        if not target_table:
             # Fallback: Just try searching all tables
             tables = soup.select("table")
             for tbl in tables:
                 if "ì ì •" in tbl.text and "ì™¸êµ­ì¸" in tbl.text:
                     target_table = tbl
                     break
                     
        if target_table:
            # Parse rows
            # Columns: ì‹œê° | ì™¸êµ­ì¸ | ê¸°ê´€ê³„
            rows = target_table.select("tr")
            for row in rows:
                cols = row.select("td")
                if len(cols) < 3: continue
                
                time_str = cols[0].text.strip()
                # Check for valid time format (e.g. 09:00, 10:30, 14:00)
                if ":" not in time_str: continue 
                
                foreigner = cols[1].text.strip()
                institution = cols[2].text.strip()
                
                # Clean numbers
                f_val = re.sub(r'[^0-9\-\+]', '', foreigner)
                i_val = re.sub(r'[^0-9\-\+]', '', institution)
                
                estimates.append({
                    "time": time_str,
                    "foreigner": int(f_val) if f_val and f_val != '-' else 0,
                    "institution": int(i_val) if i_val and i_val != '-' else 0
                })
        
        # [Fallback] If data is empty (Weekend/Closed), generate Mock Data for Demo
        if not estimates:
            import random
            print("No live data found (Market Closed?). Generating Mock Data for Demo.")
            current_hour = 9
            current_min = 30
            # Generate from 09:30 to now (or 14:30)
            mock_estimates = []
            f_accum = 0
            i_accum = 0
            
            # Create a deterministic mock based on symbol hash
            seed = sum(ord(c) for c in code)
            random.seed(seed)
            
            for _ in range(10): # up to 14:30 roughly
                time_s = f"{current_hour:02d}:{current_min:02d}"
                
                # Random flow
                f_flow = random.randint(-5000, 5000)
                i_flow = random.randint(-5000, 5000)
                
                f_accum += f_flow
                i_accum += i_flow
                
                mock_estimates.append({
                    "time": time_s,
                    "foreigner": f_accum,
                    "institution": i_accum
                })
                
                current_min += 30 # 30 min intervals
                if current_min >= 60:
                    current_hour += 1
                    current_min = 0
                
                if current_hour >= 15: break
            
            return mock_estimates

        return estimates
        
    except Exception as e:
        print(f"Live Investor Crawl Error: {e}")
        return None

def get_theme_heatmap_data():
    """
    í…Œë§ˆ íˆíŠ¸ë§µìš© ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
    ìƒìœ„ 5ê°œ í…Œë§ˆë¥¼ ê°€ì ¸ì˜¤ê³ , ê° í…Œë§ˆë³„ ìƒìœ„ 5ê°œ ì¢…ëª©ì˜ ë“±ë½ë¥ ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    (MarketDashboard ìš©)
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }
    
    heatmap_data = [] # [{theme: "AI", "percent": "+3%", stocks: [...]}, ...]
    
    try:
        # 1. Get Top Themes first from Sise Main
        sise_data = get_naver_sise_data()
        top_themes = sise_data.get("top_themes", [])[:6] # Top 6
        
        for theme in top_themes:
            theme_name = theme['name']
            theme_change = theme['percent']
            
            stocks = []
            
            # Try to get link directly from sise data
            theme_link = theme.get('link')
            
            if theme_link:
                if not theme_link.startswith("http"):
                    theme_link = "https://finance.naver.com" + theme_link
            else:
                # Fallback: Search for theme link in theme.naver
                try:
                    res = requests.get("https://finance.naver.com/sise/theme.naver", headers=headers)
                    try:
                        html = res.content.decode('utf-8')
                    except UnicodeDecodeError:
                        html = res.content.decode('cp949', 'ignore')
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    for a in soup.select("table.type_1 a"):
                        if a.text.strip() == theme_name:
                            theme_link = "https://finance.naver.com" + a['href']
                            break
                except Exception as e:
                    print(f"Theme Search Fallback Error: {e}")
            
            if theme_link:
                # 2. Fetch Stock List for this Theme
                res_sub = requests.get(theme_link, headers=headers)
                try:
                    html_sub = res_sub.content.decode('utf-8')
                except UnicodeDecodeError:
                    html_sub = res_sub.content.decode('cp949', 'ignore')
                soup_sub = BeautifulSoup(html_sub, 'html.parser')
                
                # Parse stocks table
                # Usually table.type_2 or similar
                # Columns: Name, Current Price, Change, Change Rate...
                rows = soup_sub.select("div.box_type_l table tbody tr")
                for row in rows:
                    cols = row.select("td")
                    if len(cols) < 5: continue
                    name_tag = cols[0].select_one("a")
                    if not name_tag: continue
                    
                    st_name = name_tag.text.strip()
                    # Price change rate is usually roughly in col 3 or 4
                    # Let's verify by checking spans
                    
                    # Naver Theme Detail Page Structure:
                    # Col 0: Name (with link)
                    # Col 1: Description (sometimes) -- actually the structure varies.
                    # Standard structure: Name | Price | Diff | rate | ...
                    
                    # Let's find columns with number class
                    nums = row.select("span.tah")
                    if len(nums) < 2: continue
                    
                    # Usually: Price is nums[0], Rate is nums[-1] or similar
                    # Let's try parsing text content for %
                    
                    rate_txt = ""
                    for cell in cols:
                        txt = cell.text.strip()
                        if "%" in txt:
                            rate_txt = txt
                            break
                    
                    val = re.sub(r'[^0-9\.\-\+]', '', rate_txt)
                    try:
                        rate = float(val)
                    except:
                        rate = 0.0
                        
                    stocks.append({
                        "name": st_name,
                        "change": rate
                    })
                    
                    if len(stocks) >= 5: break
            
            heatmap_data.append({
                "theme": theme_name,
                "percent": theme_change,
                "stocks": stocks
            })
            
    except Exception as e:
        print(f"Heatmap Data Error: {e}")
        
    return heatmap_data

def get_naver_flash_news():
    """
    ë„¤ì´ë²„ ê¸ˆìœµ ì£¼ìš”ë‰´ìŠ¤ í¬ë¡¤ë§ (Google News Fallbackìš©)
    URL: https://finance.naver.com/news/mainnews.naver
    """
    import requests
    from bs4 import BeautifulSoup
    
    url = "https://finance.naver.com/news/mainnews.naver"
    headers = { "User-Agent": "Mozilla/5.0" }
    news_list = []
    
    try:
        res = requests.get(url, headers=headers)
        # cp949 decoding for Naver Finance (ignore errors to be safe)
        try:
            html = res.content.decode('utf-8')
        except UnicodeDecodeError:
            html = res.content.decode('cp949', 'ignore')
        soup = BeautifulSoup(html, 'html.parser')
        
        # Select news items from Main News List
        articles = soup.select(".mainNewsList li")
        
        # Fallback selector if structure changes
        if not articles:
             articles = soup.select("ul.realtimeNewsList li")
             
        for li in articles:
            # Title extraction
            # Try finding title in dt > a or dd > a
            dt_a = li.select_one("dl dt a")
            dd_a = li.select_one("dl dd.articleSubject a")
            
            target = dd_a if dd_a else dt_a
            if not target: continue
            
            title = target.text.strip()
            link = "https://finance.naver.com" + target['href']
            
            # Source extraction
            source = "Naver Finance"
            summ = li.select_one("dd.articleSummary")
            if summ:
                press = summ.select_one(".press")
                if press: source = press.text.strip()
            
            # Simple Date Check (Naver Main News usually shows 'Today' or recent)
            # We mark it as 'ìµœì‹ ' or parse if needed. 
            # Google News expects 'time' string.
            time_str = "ìµœì‹ "
            
            news_list.append({
                "source": source,
                "title": title,
                "link": link,
                "time": time_str
            })
            
            if len(news_list) >= 10: break
            
    except Exception as e:
        print(f"Naver News Fallback Error: {e}")
        
    return news_list

def get_naver_stock_info(symbol: str):
    """
    ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì¢…ëª©ì˜ ì£¼ìš” ì‹œì„¸ ë° ì¬ë¬´ ì •ë³´(PER, EPS, PBR ë“±)ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    """
    try:
        code = symbol.split('.')[0]
        code = re.sub(r'[^0-9]', '', code)
        if len(code) != 6: return None

        url = f"https://finance.naver.com/item/main.naver?code={code}"
        headers = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)" }
        
        res = requests.get(url, headers=headers, timeout=5)
        
        # [Fix] Robust Encoding Detection (Brute Force with Keyword Check)
        content = res.content
        html = None
        decoded_ok = False
        
        # Strategy 1: Probing CP949 (Most likely for Naver Finance legacy pages)
        try:
            temp_html = content.decode('cp949')
            # Check for characteristic Korean keywords
            if "ê¸ˆìœµ" in temp_html or "ì¢…ëª©" in temp_html or "íˆ¬ì" in temp_html or "ë„¤ì´ë²„" in temp_html:
                html = temp_html
                decoded_ok = True
                print("DEBUG: Decoded as CP949 (Verified by keywords)")
        except:
            pass
            
        # Strategy 2: Probing UTF-8 (If CP949 failed or didn't look right)
        if not decoded_ok:
            try:
                temp_html = content.decode('utf-8')
                if "ê¸ˆìœµ" in temp_html or "ì¢…ëª©" in temp_html or "íˆ¬ì" in temp_html or "ë„¤ì´ë²„" in temp_html:
                    html = temp_html
                    decoded_ok = True
                    print("DEBUG: Decoded as UTF-8 (Verified by keywords)")
                elif not html: # usage fallback if cp949 completely failed
                    html = temp_html
            except:
                pass
        
        # Fallback: Use whatever requests guessed, or rigid CP949 with ignore
        if not html:
            print("DEBUG: Encoding detection failed, falling back to forceful CP949 decode")
            html = content.decode('cp949', 'ignore')

        soup = BeautifulSoup(html, 'html.parser')

        # [Fix] Explicitly check for Naver's "Temporary Error" page with robust text matching
        if "ì¼ì‹œì ì¸ ì˜¤ë¥˜" in html or "ì„œë¹„ìŠ¤ ì´ìš©ì— ë¶ˆí¸" in html:
            print(f"Naver Block/Temporary Error Detected for {symbol}")
            return None

        
        info = { 
            "symbol": symbol, "currency": "KRW", 
            "market_cap_val": 0, "market_cap_str": "N/A",
            "per": None, "eps": None, "pbr": None, "dvr": None 
        }
        
        # 1. Name
        h2 = soup.select_one(".wrap_company h2 a")
        if h2: info['name'] = h2.text.strip()
        
        # 2. Price
        no_today = soup.select_one(".no_today .blind")
        if no_today: info['price'] = int(re.sub(r'[^0-9]', '', no_today.text))
        else: return None # Price is essential
        
        # 3. Change & Percent
        exday = soup.select_one(".no_exday")
        if exday:
           blind_tags = exday.select(".blind")
           if len(blind_tags) >= 2:
               diff = int(re.sub(r'[^0-9]', '', blind_tags[0].text))
               pct = blind_tags[1].text.strip()
               
               is_down = "nv" in str(exday) or "í•˜ë½" in exday.text
               if is_down:
                   info['change'] = -diff
                   info['change_percent'] = f"-{pct}%"
               else:
                   info['change'] = diff
                   info['change_percent'] = f"+{pct}%"
        
        # 4. Prev Close calculation
        if 'price' in info and 'change' in info:
            info['prev_close'] = info['price'] - info['change']

        # 5. Details (ID selectors are reliable on Naver Finance Item Main)
        # Market Cap: #_market_sum
        # PER: #_per, EPS: #_eps, PBR: #_pbr, DivYield: #_dvr
        
        mc_tag = soup.select_one("#_market_sum")
        if mc_tag:
            mc_text = mc_tag.text.strip().replace('\t','').replace('\n','')
            info['market_cap_str'] = mc_text
            # Parse to value
            val = 0
            # ex: "384ì¡° 3,111"
            parts = mc_text.split('ì¡°')
            if len(parts) > 1:
                jo = int(re.sub(r'[^0-9]', '', parts[0])) * 1000000000000
                uk_str = re.sub(r'[^0-9]', '', parts[1])
                uk = int(uk_str) * 100000000 if uk_str else 0
                val = jo + uk
            else:
                 info['market_cap_val'] = int(re.sub(r'[^0-9]', '', mc_text)) * 100000000
            info['market_cap_val'] = val

        per_tag = soup.select_one("#_per")
        if per_tag: 
            try: info['per'] = float(per_tag.text.strip().replace(',', ''))
            except: info['per'] = None
        
        eps_tag = soup.select_one("#_eps")
        if eps_tag: 
            try: info['eps'] = float(eps_tag.text.strip().replace(',', ''))
            except: info['eps'] = None
        
        pbr_tag = soup.select_one("#_pbr")
        if pbr_tag: 
            try: info['pbr'] = float(pbr_tag.text.strip().replace(',', ''))
            except: info['pbr'] = None
        
        dvr_tag = soup.select_one("#_dvr") # Dividend Yield
        if dvr_tag: 
            try: info['dvr'] = float(dvr_tag.text.strip().replace(',', ''))
            except: info['dvr'] = None
        
        return info

    except Exception as e:
        print(f"Naver Stock Info Crawl Error: {e}")
        return None
 
 d e f   g e t _ n a v e r _ d a i l y _ p r i c e s ( s y m b o l :   s t r ) :  
         " " "  
         ? |1 Å0? rnI³VÄ  áùf$Ã´  A P I \t? ? ï´P¾  ? ğÁĞ  ? –Äm¯\t? ›Z€ ? „ºÃÀ? H³µ.   ( äù“Ä¸  3 0 ? ?  
         " " "  
         c o d e   =   s y m b o l . s p l i t ( ' . ' ) [ 0 ]  
         c o d e   =   r e . s u b ( r ' [ ^ 0 - 9 ] ' ,   ' ' ,   c o d e )  
         i f   l e n ( c o d e )   ! =   6 :   r e t u r n   [ ]  
  
         u r l   =   f " h t t p s : / / f c h a r t . s t o c k . n a v e r . c o m / s i s e . n h n ? s y m b o l = { c o d e } & t i m e f r a m e = d a y & c o u n t = 3 0 & r e q u e s t T y p e = 0 "  
          
         t r y :  
                 i m p o r t   r e q u e s t s  
                 i m p o r t   x m l . e t r e e . E l e m e n t T r e e   a s   E T  
                  
                 r e s   =   r e q u e s t s . g e t ( u r l )  
                 i f   r e s . s t a t u s _ c o d e   = =   2 0 0 :  
                         r o o t   =   E T . f r o m s t r i n g ( r e s . t e x t )  
                          
                         p a r s e d _ d a t a   =   [ ]  
                         i t e m s   =   r o o t . f i n d a l l ( " i t e m " )  
                          
                         f o r   i t e m   i n   i t e m s :  
                                 d a t a _ s t r   =   i t e m . g e t ( " d a t a " )  
                                 i f   d a t a _ s t r :  
                                         p a r t s   =   d a t a _ s t r . s p l i t ( " | " )  
                                         #   d a t a   f o r m a t :   Y Y Y Y M M D D | O p e n | H i g h | L o w | C l o s e | V o l u m e  
                                         i f   l e n ( p a r t s )   > =   6 :  
                                                 p a r s e d _ d a t a . a p p e n d ( {  
                                                         " d a t e " :   f " { p a r t s [ 0 ] [ : 4 ] } - { p a r t s [ 0 ] [ 4 : 6 ] } - { p a r t s [ 0 ] [ 6 : ] } " ,  
                                                         " o p e n " :   f l o a t ( p a r t s [ 1 ] ) ,  
                                                         " h i g h " :   f l o a t ( p a r t s [ 2 ] ) ,  
                                                         " l o w " :   f l o a t ( p a r t s [ 3 ] ) ,  
                                                         " c l o s e " :   f l o a t ( p a r t s [ 4 ] ) ,  
                                                         " v o l u m e " :   i n t ( p a r t s [ 5 ] )  
                                                 } )  
                          
                         #   C a l c u l a t e   m e t r i c s   ( C h a n g e   % )  
                         f i n a l _ l i s t   =   [ ]  
                         f o r   i   i n   r a n g e ( l e n ( p a r s e d _ d a t a ) ) :  
                                 c u r r   =   p a r s e d _ d a t a [ i ]  
                                 #   F o r   t h e   f i r s t   i t e m ,   w e   m i g h t   n o t   h a v e   p r e v   c l o s e ,   a s s u m e   0   c h a n g e   o r   b a s e d   o n   O p e n  
                                 p r e v _ c l o s e   =   p a r s e d _ d a t a [ i - 1 ] [ " c l o s e " ]   i f   i   >   0   e l s e   c u r r [ " o p e n " ]  
                                  
                                 c h a n g e   =   0 . 0  
                                 i f   p r e v _ c l o s e   >   0 :  
                                         c h a n g e   =   ( ( c u r r [ " c l o s e " ]   -   p r e v _ c l o s e )   /   p r e v _ c l o s e )   *   1 0 0  
                                          
                                 f i n a l _ l i s t . a p p e n d ( {  
                                         " d a t e " :   c u r r [ " d a t e " ] ,  
                                         " o p e n " :   c u r r [ " o p e n " ] ,  
                                         " h i g h " :   c u r r [ " h i g h " ] ,  
                                         " l o w " :   c u r r [ " l o w " ] ,  
                                         " c l o s e " :   c u r r [ " c l o s e " ] ,  
                                         " v o l u m e " :   c u r r [ " v o l u m e " ] ,  
                                         " c h a n g e " :   c h a n g e  
                                 } )  
                          
                         #   R e t u r n   n e w e s t   f i r s t  
                         r e t u r n   f i n a l _ l i s t [ : : - 1 ]  
  
         e x c e p t   E x c e p t i o n   a s   e :  
                 p r i n t ( f " N a v e r   D a i l y   P r i c e   E r r o r :   { e } " )  
                 r e t u r n   [ ]  
 